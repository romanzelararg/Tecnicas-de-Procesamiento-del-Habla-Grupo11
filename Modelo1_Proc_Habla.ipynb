{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romanzelararg/Tecnicas-de-Procesamiento-del-Habla-Grupo11/blob/main/Modelo1_Proc_Habla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo clasificador de Bosque Aleatorio"
      ],
      "metadata": {
        "id": "1IA3UAGJO7Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh3Lp7XujOxj",
        "outputId": "89e7d68f-225a-44a3-c881-b39bf899f370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importación de bibliotecas\n",
        "\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "libro = \"/content/drive/MyDrive/Colab Notebooks/24 horas en la vida de una mujer.txt\"\n",
        "with open(libro, 'r') as f:\n",
        "    texto = f.read()\n",
        "tokens = nltk.word_tokenize(texto) #Se tokeniza el texto utilizando la función\n",
        "\n",
        "# Extracción de características. Se utiliza TfidfVectorizer para convertir los tokens en una matriz TF-IDF.\n",
        "#Cada fila de la matriz representa un token y cada columna representa un documento (en este caso, fragmentos de texto).\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(tokens)\n",
        "\n",
        "# Definir las etiquetas de clase\n",
        "\"\"\"Por ejemplo, palabras como “bueno”, “feliz” y “contento” se etiquetan como 1 (sentimiento positivo),\n",
        "mientras que palabras como “Irritado” y “mal” se etiquetan como 0 (sentimiento negativo).\"\"\"\n",
        "\n",
        "etiquetas_sentimiento = {\n",
        "    'bueno': 1,\n",
        "    'feliz': 1,\n",
        "    'contento':1,\n",
        "    'amable':1,\n",
        "    'Irritado':0,\n",
        "    'mal': 0,\n",
        "    'triste': 0,\n",
        "    'malo':0,\n",
        "    'enojado':0\n",
        "    # Agrega más palabras y etiquetas según sea necesario\n",
        "}\n",
        "y = np.array([etiquetas_sentimiento[token] if token in etiquetas_sentimiento else -1 for token in tokens])\n",
        "\n",
        "# Eliminar los tokens con etiqueta -1\n",
        "#Se filtran los tokens que no tienen una etiqueta válida (es decir, aquellos que no están en el diccionario etiquetas_sentimiento).\n",
        "X = X[y != -1]\n",
        "y = y[y != -1]\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el clasificador de Bosque Aleatorio\n",
        "#Se crea un clasificador de Bosque Aleatorio con 100 árboles.\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en datos de prueba\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Se calcula la precisión del modelo utilizando la función accuracy_score.\n",
        "precision = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: %.2f' % (precision * 100))"
      ],
      "metadata": {
        "id": "NvDCAlRDM1ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ea90c6-2d84-4a3a-daad-bab9b739b74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00\n"
          ]
        }
      ]
    }
  ]
}